{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "appropriate-lighting",
   "metadata": {},
   "source": [
    "# Optimisation\n",
    "\n",
    "This part is to look at the resources needed to apply some methods to obtain the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-preference",
   "metadata": {},
   "source": [
    "We first load the functions and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flush-zoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"schedule_lib.jl\")\n",
    "using BenchmarkTools\n",
    "\n",
    "students_filename = \"examparams.xlsx\"\n",
    "prof_filename = \"professors.xlsx\"\n",
    "function get_data()\n",
    "    professors = import_prof(prof_filename)\n",
    "    s = import_excel(students_filename,professors)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-guarantee",
   "metadata": {},
   "source": [
    "## Simple backtracking\n",
    "\n",
    "We first use the backtracking with the constraints only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arbitrary-extra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  9.10 MiB\n",
       "  allocs estimate:  83272\n",
       "  --------------\n",
       "  minimum time:     11.594 ms (0.00% GC)\n",
       "  median time:      12.026 ms (0.00% GC)\n",
       "  mean time:        12.923 ms (5.66% GC)\n",
       "  maximum time:     19.930 ms (22.26% GC)\n",
       "  --------------\n",
       "  samples:          387\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_data()\n",
    "@benchmark backtracking_search($s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-island",
   "metadata": {},
   "source": [
    "## Backtracking with MCV\n",
    "\n",
    "We now apply the backtracking with MVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "radical-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  115.06 MiB\n",
       "  allocs estimate:  994061\n",
       "  --------------\n",
       "  minimum time:     209.515 ms (3.30% GC)\n",
       "  median time:      215.477 ms (4.96% GC)\n",
       "  mean time:        217.531 ms (4.35% GC)\n",
       "  maximum time:     270.947 ms (4.71% GC)\n",
       "  --------------\n",
       "  samples:          24\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_data()\n",
    "@benchmark backtracking_search($s,inference=$full_filtering!,select_unassigned_variable=$MCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-fireplace",
   "metadata": {},
   "source": [
    "## Backtracking with MCV and LCV\n",
    "\n",
    "We now apply the backtracking with MVC and LCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turkish-tragedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.36 GiB\n",
       "  allocs estimate:  11681642\n",
       "  --------------\n",
       "  minimum time:     2.877 s (3.86% GC)\n",
       "  median time:      2.879 s (3.78% GC)\n",
       "  mean time:        2.879 s (3.78% GC)\n",
       "  maximum time:     2.880 s (3.69% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_data()\n",
    "@benchmark backtracking_search($s,inference=$full_filtering!,\n",
    "    select_unassigned_variable=$MCV,order_domain_values=$LCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-marble",
   "metadata": {},
   "source": [
    "## Backtracking with arc consistency\n",
    "\n",
    "We now apply the backtracking with arc consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "responsible-complaint",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: apply_prep! not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: apply_prep! not defined",
      "",
      "Stacktrace:",
      "  [1] apply_arc_consistency!(s::Schedule)",
      "    @ Main /shared_data/Documents/ERM/1Ma/DS425/project/ExamTimetable/schedule_lib.jl:205",
      "  [2] backtracking_search(s::Schedule; select_unassigned_variable::Function, order_domain_values::Function, inference::typeof(apply_arc_consistency!))",
      "    @ Main /shared_data/Documents/ERM/1Ma/DS425/project/ExamTimetable/schedule_lib.jl:568",
      "  [3] var\"##core#295\"(s#293::Schedule, apply_arc_consistency!#294::typeof(apply_arc_consistency!))",
      "    @ Main ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:479",
      "  [4] var\"##sample#296\"(__params::BenchmarkTools.Parameters)",
      "    @ Main ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:485",
      "  [5] _run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{4, Symbol}, NamedTuple{(:samples, :evals, :gctrial, :gcsample), Tuple{Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:98",
      "  [6] #invokelatest#2",
      "    @ ./essentials.jl:710 [inlined]",
      "  [7] #run_result#38",
      "    @ ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:33 [inlined]",
      "  [8] run(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol, Integer, NTuple{5, Symbol}, NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample), Tuple{Bool, Int64, Int64, Bool, Bool}}})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:116",
      "  [9] #warmup#47",
      "    @ ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:168 [inlined]",
      " [10] warmup(item::BenchmarkTools.Benchmark)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:168",
      " [11] top-level scope",
      "    @ ~/.julia/packages/BenchmarkTools/ms0Xc/src/execution.jl:387",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "s = get_data()\n",
    "@benchmark backtracking_search($s,inference=$apply_arc_consistency!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-philadelphia",
   "metadata": {},
   "source": [
    "## Backtracking with arc consistency and MVC\n",
    "\n",
    "We now apply the backtracking with arc consistency and MVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustained-trading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.56 GiB\n",
       "  allocs estimate:  26743083\n",
       "  --------------\n",
       "  minimum time:     1.687 s (13.70% GC)\n",
       "  median time:      1.710 s (14.10% GC)\n",
       "  mean time:        1.717 s (14.00% GC)\n",
       "  maximum time:     1.755 s (14.17% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = get_data()\n",
    "@benchmark backtracking_search($s,inference=$apply_arc_consistency!,\n",
    "    select_unassigned_variable=$MCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
